{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c972e7a6",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "## Intro to LangChain\n",
    "\n",
    "* LangChain is open-source framework designed to build applications w/LLMs\n",
    "* offers generic interface for LLMs, providing unified way of working w/ external datasets and workflows\n",
    "* facilitates tools and methods to customize and improve the generated models for better accuracy and relevance\n",
    "* overall, simplifies integration of LLMs, provides advanced AI/ML capabilities wo/ heavy implementation overhead, enhances flexibility and freedom to experiment, customize and build commercial products\n",
    "\n",
    "* Components\n",
    "    * Chains, agents, and retrieval\n",
    "        * used to construct an app's architecture (how it processes and retrieves information)\n",
    "    * Core\n",
    "        * base expression language and abstraction layer for building upon LangChain\n",
    "    * Community\n",
    "        * third party integrations (LC IBM, LC OpenAI, LC Anthropic)\n",
    "        * packages built on top of the Core\n",
    "\n",
    "* Use-cases\n",
    "    * chatbots & AI agents -> enhance interactions and automate responses\n",
    "    * API integration -> connect LLM app to various services\n",
    "    * data insights -> understand code, queries and tabular data to extract insights\n",
    "    * document QA & summarization -> ask questions about documents or retrieve/summarize large texts\n",
    "    * manage and organize vast content libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e4456d",
   "metadata": {},
   "source": [
    "## Core concepts\n",
    "\n",
    "### In-context learning\n",
    "\n",
    "* prompt engineering where task demonstrations are included withing the prompt at inference time, no additional training\n",
    "* advantages -> reduces resources/time (no fine-tuning), disadvantages -> context size limit\n",
    "\n",
    "* fundamentals of prompt engineering\n",
    "    * prompt are instructions or inputs given to an LLM to guid it toward a specific task or output\n",
    "    * components\n",
    "        * instructions -> command\n",
    "        * context -> relevant details (data, domain info)\n",
    "    * prompt engineering is a process of designing and refining prompts, it aims for clear and contextually rich prompts to get relevant, accurate responses\n",
    "\n",
    "* structured prompt\n",
    "    * instructions -> direct task (classify the following text as positive, neutral or negative)\n",
    "    * context -> background info or scenario (the product is new, so the feedback might vary)\n",
    "    * input data -> text or data to be processed (customer review)\n",
    "    * output -> what type of output is needed (sentiment)\n",
    "\n",
    "### Advanced prompt engineering\n",
    "\n",
    "* zero-shot prompting\n",
    "    * the model performs task without any specific prior example\n",
    "    * \"Is the eiffel tower in Berlin? Classify as True or False.\"\n",
    "    * relying on general knowledge of the LLM\n",
    "* one-shot prompting\n",
    "    * a single example is provided before the actual query\n",
    "    * provide one sample translation from en to fr, then ask the model to translate a new sentence\n",
    "* few-shots prompting\n",
    "    * a small set of examples is provided to illustrate the task\n",
    "    * show multiple statements labeled with emotions, the model then labels a new statement based on those patterns\n",
    "* chain-of-thought prompting\n",
    "    * encourages LLM to reason through a problem step-by step, mimicking a human thought process\n",
    "    * helps with complex or multi-step problems (arithmetic word problems)\n",
    "* self-consistency\n",
    "    * the model generates multiple solutions to the same prompt, then cross-verifies them to find the most consistent or correct result\n",
    "    * improves reliability by comparing different reasoning paths\n",
    "\n",
    "* tools & apps\n",
    "    * OpenAI playground, LangChain, HF model hub, IBM AI classroom\n",
    "        * allow prompt development, experimentation, and immediate output eval\n",
    "        * wide range of pre-trained models and support of collaborative prompt refinement\n",
    "    * LangChain for prompt templates\n",
    "        * offers structured, reusable templates (instruction + examples + placeholders)\n",
    "        * simplifies prompt creation for various tasks (jokes, QA, summarization)\n",
    "    \n",
    "* agents\n",
    "    * LLM entities that use prompts and additional tools to perform complex tasks\n",
    "    * examples\n",
    "        * QA agents, content agents, analytic agents, multilingual agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704cef7",
   "metadata": {},
   "source": [
    "## LangChain Core\n",
    "\n",
    "* open-source interface that simplifies application dev process with LLMs, integrates LLMs into various use-cases through structured components\n",
    "\n",
    "* components\n",
    "    * language model\n",
    "        * foundational layer in LangChain that uses text input to generate text output, LLM model of choice\n",
    "        \n",
    "    * chat model\n",
    "        * language model designed for conversational interactions\n",
    "\n",
    "    * chat messages\n",
    "        * different message types\n",
    "            * HumanMessage -> user input/questions\n",
    "            * AIMessage -> responses generated by the model\n",
    "            * SystemMessage -> instructions or context to the model\n",
    "            * FunctionMessage -> used when the model calls a function with specific params\n",
    "            * ToolMessage -> facilitates interactions with external tools or APIs\n",
    "        * each message has speaker (role) and text (content)\n",
    "\n",
    "    * prompt templates\n",
    "        * help translate user request into clear, structure instructions for the LLM\n",
    "        * types\n",
    "            * StringPromptTemplate -> for single string formatting\n",
    "            * ChatPromptTemplate -> for message lists with roles\n",
    "            * MessagePromptTemplate -> eg AIMessagePromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "            * FewShotPromptTemplate -> includes examples (\"shots) that guide the LLMs output\n",
    "\n",
    "    * example selector\n",
    "        * dynamically pics examples from a library to guide the LLM for the task at hand\n",
    "        * methods include semantic similarity, max marginal relevance, n-gram overlap etc\n",
    "\n",
    "    * output parser\n",
    "        * convert LLM outputs into structured formats (JSON, XML, CSV, Pandas DF)\n",
    "        * CommaSeparatedListOutputParser transforms output into CSV\n",
    "\n",
    "## LangChain documents for RAG apps\n",
    "\n",
    "* document object\n",
    "    * stores data in `page_content` (string text), `metadata` (arbitrary attributes like doc_id, filename etc)\n",
    "* document loader\n",
    "    * pulls docs from diverse sources (HTML, PDF, code, storage, web, ...)\n",
    "    * 100+ loaders supported\n",
    "* text splitter\n",
    "    * splits large docs into chunks for efficient retrieval\n",
    "    * examples\n",
    "        * RecursiveCharacterTextSplitter (splits text recursively)\n",
    "        * MarkdownHeaderTextSplitter (splits mark-down text by headers) etc\n",
    "* embeddings & vec database\n",
    "    * embeddings -> capture semantic meaning of text\n",
    "    * vector database -> stores document embeddings for fast similarity search\n",
    "    * example\n",
    "        * Chroma for storing embeddings and performing similarity queries\n",
    "* retriever\n",
    "    * retrieves stored data from the vector db or chunked docs\n",
    "    * supports different strategies (vector store retriever, parent document retriever, self-query retriever)\n",
    "\n",
    "## Chains and agents for apps\n",
    "\n",
    "* chains\n",
    "    * sequence of calls where each step's output is the next step's input (sequential flow)\n",
    "    * example -> three-step chain to identify a famous dish, provide its recipe, and estimate cooking time\n",
    "        * chain 1 -> takes user's location -> outputs a famous local dish\n",
    "        * chain 2 -> takes that dish name -> outputs a recipe\n",
    "        * chain 3 -> takes that recipe -> outputs cooking time\n",
    "    * verbose mode -> allows seeing intermediate ouputs for clarity\n",
    "\n",
    "* memory\n",
    "    * maintains conversation context\n",
    "    * ChatMessageHIstory -> stores AIMessage and HUmanMessage in the conversation history\n",
    "    * each chain can read and write to memory, preserving continuity across interactions\n",
    "\n",
    "* agents\n",
    "    * dynamic systems where LLM decides which actions to take\n",
    "    * integrates with external tools (search engines, databases, APIs) to ful-fill tasks\n",
    "    * example\n",
    "        * Pandas DataFrame Agent\n",
    "            * processes natural language queries on DFs by converting them to python code in the background\n",
    "            * \"How many rows are in the DataFrame?\" -> LLM outputs code, agent executes -> returns result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
