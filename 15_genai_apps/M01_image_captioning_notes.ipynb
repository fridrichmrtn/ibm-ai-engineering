{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075b1fe5",
   "metadata": {},
   "source": [
    "# Image captioning with GenAI\n",
    "\n",
    "* core GenAI models\n",
    "    * variational autoencoders\n",
    "        * input data -> encoder -> latent space -> decoder -> reconstructed data\n",
    "        * image synthesis, data compression, anomaly detection\n",
    "    * generative adversarial networks\n",
    "        * data -> generator -> generated data -> discriminator -> decision if generated data\n",
    "        * image generation, timeseries generation, challenging to train\n",
    "    * transformer-based models\n",
    "        * attention mechanism for leveriging relationship within a sequence\n",
    "        * text, picture, music, video synthesis and generation\n",
    "    * diffusion models\n",
    "        * address systematic decay of data due to noise in the latent space\n",
    "        * removing noise from the data, similar to VAR but using flow process for training\n",
    "        * image & video generation\n",
    "\n",
    "* foundational models\n",
    "    * new successful paradigm for building AI system, that uses a large amount of data and can be used for any applications\n",
    "    * process of building a foundation model\n",
    "        * pretraining\n",
    "            * unsupervised learning\n",
    "            * diverse training data\n",
    "            * multidomain -> Q&A, text summarization, solving equations, coding, ...\n",
    "            * multimodal -> text, image, audio, video\n",
    "            * can be adapted to new use-cases\n",
    "        * posttraining\n",
    "            * RL & others\n",
    "    * architectures -> LLMs vs diffusion (image-gen)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
